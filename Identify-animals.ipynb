{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /Users/keerthanamanoharan/.cache/kagglehub/datasets/andrewmvd/animal-faces/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "dataset_path = kagglehub.dataset_download(\"andrewmvd/animal-faces\")\n",
    "print(\"Dataset path:\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/keerthanamanoharan/.cache/kagglehub/datasets/andrewmvd/animal-faces/versions/1\n"
     ]
    }
   ],
   "source": [
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qqwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16130 files belonging to 1 classes.\n",
      "Using 12904 files for training.\n",
      "Found 16130 files belonging to 1 classes.\n",
      "Using 3226 files for validation.\n",
      "class_names\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Dataset path (replace this with the real path if needed)\n",
    "data_dir = os.path.expanduser(dataset_path)\n",
    "\n",
    "# Load dataset from directory\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Class Name\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"class_names\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to [0, 1]\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keerthanamanoharan/Desktop/FromClass/Repos/identify-animal-in-pics/venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 363ms/step - accuracy: 0.1004 - loss: 0.0000e+00 - val_accuracy: 0.1135 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 369ms/step - accuracy: 0.1009 - loss: 0.0000e+00 - val_accuracy: 0.1135 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 366ms/step - accuracy: 0.1012 - loss: 0.0000e+00 - val_accuracy: 0.1135 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 373ms/step - accuracy: 0.1004 - loss: 0.0000e+00 - val_accuracy: 0.1135 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 368ms/step - accuracy: 0.1012 - loss: 0.0000e+00 - val_accuracy: 0.1135 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 370ms/step - accuracy: 0.1013 - loss: 0.0000e+00 - val_accuracy: 0.1135 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 375ms/step - accuracy: 0.1012 - loss: 0.0000e+00 - val_accuracy: 0.1135 - val_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 584ms/step - accuracy: 0.1011 - loss: 0.0000e+00 - val_accuracy: 0.1135 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 371ms/step - accuracy: 0.1012 - loss: 0.0000e+00 - val_accuracy: 0.1135 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 370ms/step - accuracy: 0.1007 - loss: 0.0000e+00 - val_accuracy: 0.1135 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#Build and Train the CNN Model\n",
    "num_classes = len(train_ds.class_names)  # e.g., 3 for cat, dog, panda\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Validation Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the Model\n",
    "loss, accuracy = model.evaluate(val_ds)\n",
    "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 95ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        afhq       1.00      1.00      1.00      3226\n",
      "\n",
      "    accuracy                           1.00      3226\n",
      "   macro avg       1.00      1.00      1.00      3226\n",
      "weighted avg       1.00      1.00      1.00      3226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analyze and Reflect\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# True labels\n",
    "y_true = np.concatenate([y.numpy() for x, y in val_ds])\n",
    "# Predictions\n",
    "y_pred_logits = model.predict(val_ds)\n",
    "y_pred = np.argmax(y_pred_logits, axis=1)\n",
    "\n",
    "# Print report  \n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: Animal Faces from Kaggle (cats, dogs, pandas)\n",
    "\n",
    "Model: CNN trained from scratch using Keras\n",
    "\n",
    "Accuracy: Reported on validation set + detailed classification metrics\n",
    "\n",
    "Improvements:\n",
    "\n",
    "Add data augmentation\n",
    "\n",
    "Use transfer learning with MobileNet or ResNet\n",
    "\n",
    "Hyperparameter tuning (more epochs, different optimizers, etc.)\n",
    "\n",
    "Would you like me to show this using transfer learning (for higher accuracy), or do you want to visualize predictions with images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
